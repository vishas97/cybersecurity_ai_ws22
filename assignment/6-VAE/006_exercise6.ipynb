{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355ed73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:01.493934Z",
     "start_time": "2022-12-02T12:35:59.951883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 13:36:00.101913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 13:36:00.164770: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers, losses, optimizers\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5279b63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:02.210857Z",
     "start_time": "2022-12-02T12:36:01.496079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,143,812\n",
      "Trainable params: 1,143,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 13:36:01.614376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 13:36:02.049565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14349 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def make_encoder(input_shape=(28,28,1), latent_dim=2):\n",
    "    inx = Input(input_shape)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(inx)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(2*latent_dim)(x)\n",
    "    return Model(inx, x)\n",
    "\n",
    "enc = make_encoder()\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d810c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:02.304990Z",
     "start_time": "2022-12-02T12:36:02.214047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1536      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              1050624   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 64)         73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " cropping2d (Cropping2D)     (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,144,705\n",
      "Trainable params: 1,144,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_decoder(input_shape=(28,28,1), latent_dim=2):\n",
    "    inx = Input(latent_dim)\n",
    "    x = layers.Dense(512, activation='relu')(inx)\n",
    "    x = layers.Dense(2048, activation='relu')(x)\n",
    "    x = layers.Reshape((4,4,128))(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Cropping2D(cropping=(1, 1))(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, strides=2, padding='same', activation=None)(x)\n",
    "    return Model(inx, x)\n",
    "\n",
    "dec = make_decoder()\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28de5a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:17.915386Z",
     "start_time": "2022-12-02T12:36:17.901882Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent_dim = self.decoder.input.shape[-1]\n",
    "        \n",
    "    def call(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.sample(mean, logvar)\n",
    "        x_ = self.decoder(z)\n",
    "        kl_loss = self.kl_analytic(mean, logvar)\n",
    "        self.add_loss(tf.reduce_mean(kl_loss))\n",
    "        self.add_metric(kl_loss, name='kl')\n",
    "        return x_\n",
    "    \n",
    "    def kl_analytic(self, mean, logvar):\n",
    "        kl = -.5*tf.reduce_mean(logvar - tf.square(mean) - tf.exp(logvar) + 1, axis=[1])\n",
    "        return kl\n",
    "        \n",
    "    def sample(self, mean, logvar):\n",
    "        batch_size = tf.shape(mean)[0]\n",
    "        eps = tf.random.normal((batch_size, self.latent_dim))\n",
    "        return eps*tf.exp(logvar*.5) + mean\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=-1)\n",
    "        return mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f787cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:39:00.019655Z",
     "start_time": "2022-12-02T12:39:00.013390Z"
    }
   },
   "outputs": [],
   "source": [
    "class MSELoss(losses.Loss):\n",
    "    \n",
    "    def call(x_true, x_rec):\n",
    "        loss = tf.sum(tf.square(x_true-x_rec), axis=[1,2,3])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67afd1da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:39:02.755412Z",
     "start_time": "2022-12-02T12:39:02.710394Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = MSELoss()\n",
    "opt = optimizers.Adam(learning_rate=1e-3)\n",
    "vae = VAE(enc, dec)\n",
    "vae.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fc0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:22:11.414759Z",
     "start_time": "2022-12-02T12:22:11.403173Z"
    }
   },
   "source": [
    " - Load the MNIST dataset, rescale the values to lie [0,1] and split into train/test/rest sets (10000/1000/-1).\n",
    " - Train the VAE model, visualize the latent space and plot some inputs and their reconstruction.\n",
    " - Sample the latent space in a rectangluar grid and generate synthetic samples. Visualize them.\n",
    " - Binarize the MNIST dataset. What is the appropriate loss function for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24f959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:02.318097Z",
     "start_time": "2022-12-02T12:36:02.318069Z"
    }
   },
   "outputs": [],
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5b285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:02.320982Z",
     "start_time": "2022-12-02T12:36:02.320953Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07838c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T12:36:02.323166Z",
     "start_time": "2022-12-02T12:36:02.323137Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ea2a9",
   "metadata": {},
   "source": [
    " - Train a classifier on the training data and on 10000 synthetic data points\n",
    " - Compare their performance on the test set\n",
    " Hint: Ensure that the synthetic data looks the same as the original data (values in [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bafeae5",
   "metadata": {},
   "source": [
    " - Modify the VAE model to take a parameter beta that weights the KL-Term\n",
    " - Experiment with different values of beta. How does the reconstruction quality change? What about the latent embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a36747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a9c670",
   "metadata": {},
   "source": [
    "Is synthetic data generation sufficient to guarantee privacy? What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
